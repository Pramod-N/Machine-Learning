{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad2bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f9876",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a390cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "\n",
    "X, y = data['data'],data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fcfb96",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96828e38",
   "metadata": {},
   "source": [
    "Lets visualize what type of distribution does sepal length has. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "815f7bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  4., 12., 29., 20., 24., 26., 18.,  9.,  3.,  5.,  0.]),\n",
       " array([3.3, 3.7, 4.1, 4.5, 4.9, 5.3, 5.7, 6.1, 6.5, 6.9, 7.3, 7.7, 8.1,\n",
       "        8.5]),\n",
       " <BarContainer object of 13 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD5CAYAAAA+0W6bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANOUlEQVR4nO3df6jd9X3H8edrSbZWa6niVe6MMV0RmQym5eK6CaWbtbNdqHbgqDAJwxH/qEW3wnT9p/1ToT/2zxBSdQZm7ZxVKkFaxXU4ochurGhcLHYu0cSYXOc67RhU43t/3G9GuL035+Sc883J597nAw7nnO/93u95f4k+/frN95yTqkKS1J5fmfYAkqTRGHBJapQBl6RGGXBJapQBl6RGGXBJatT6QSskeR/wJPBr3foPVtVXkpwF/AOwGdgL/ElV/dfxtnX22WfX5s2bxxxZktaWXbt2vVFVM0uXZ9B14EkCnF5VP0+yAXgKuBn4Y+DNqro9yW3AmVV16/G2NTc3V/Pz8yPvhCStRUl2VdXc0uUDT6HUop93Tzd0twKuBnZ0y3cA10xmVEnSMIY6B55kXZJngcPA41X1NHBuVR0E6O7P6W1KSdIvGSrgVXWkqi4BNgKXJfmtYV8gybYk80nmFxYWRhxTkrTUCV2FUlU/A/4ZuAo4lGQWoLs/vMLvbK+quaqam5n5pXPwkqQRDQx4kpkkH+oevx/4JPAi8AiwtVttK/C9nmaUJC1j4GWEwCywI8k6FoP/QFXtTPIj4IEkNwCvANf2OKckaYmBAa+q54BLl1n+n8AVfQwlSRrMd2JKUqMMuCQ1yoDruGY3biJJL7fZjZumvXtS04b5S0ytYa8feJULbt3Zy7b33bGll+1Ka4VH4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMuSY0y4JLUKAMujcAve9apwC81lkbglz3rVOARuCQ1yoBLUqMGBjzJ+Ul+mGRPkheS3Nwt/2qSA0me7W6f6X9cSdJRw5wDfxf4UlU9k+QMYFeSx7uffbOqvtbfeJKklQwMeFUdBA52j99Osgc4r+/BJEnHd0LnwJNsBi4Fnu4W3ZTkuST3JDlzhd/ZlmQ+yfzCwsJ400qS/t/QAU/yAeC7wC1V9RZwJ/AR4BIWj9C/vtzvVdX2qpqrqrmZmZnxJ5YkAUMGPMkGFuN9X1U9BFBVh6rqSFW9B3wLuKy/MSVJSw1zFUqAu4E9VfWNY5bPHrPa54Ddkx9PkrSSYa5CuRy4Hng+ybPdsi8D1yW5BChgL3BjD/NJklYwzFUoTwFZ5kePTn4cSdKwfCemJDXKgGvV6vMTA6VTgZ9GqFXLTwzUaucRuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMGBjzJ+Ul+mGRPkheS3NwtPyvJ40le6u7P7H9cSdJRwxyBvwt8qap+E/gY8IUkFwO3AU9U1YXAE91zSdJJMjDgVXWwqp7pHr8N7AHOA64GdnSr7QCu6WlGSdIy1p/Iykk2A5cCTwPnVtVBWIx8knNW+J1twDaATZs2jTWsVpl1G0gy7SmkZg0d8CQfAL4L3FJVbw37L15VbQe2A8zNzdUoQ2qVOvIOF9y6s7fN77tjS2/blk4FQ12FkmQDi/G+r6oe6hYfSjLb/XwWONzPiJKk5QxzFUqAu4E9VfWNY370CLC1e7wV+N7kx5MkrWSYUyiXA9cDzyd5tlv2ZeB24IEkNwCvANf2MqEkaVkDA15VTwErnfC+YrLjSJKG5TsxJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXApVNN9ymNfd1mN/qpoKvFCX2crKSTwE9p1JA8ApekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWrUwIAnuSfJ4SS7j1n21SQHkjzb3T7T75iSpKWGOQK/F7hqmeXfrKpLutujkx1LkjTIwIBX1ZPAmydhFknSCRjnHPhNSZ7rTrGcObGJJElDGTXgdwIfAS4BDgJfX2nFJNuSzCeZX1hYGPHlJElLjRTwqjpUVUeq6j3gW8Blx1l3e1XNVdXczMzMqHNKkpYYKeBJZo95+jlg90rrSpL6sX7QCknuBz4BnJ1kP/AV4BNJLgEK2Avc2N+IkqTlDAx4VV23zOK7e5hFknQCfCemJDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowx442Y3biJJbzdJp66B38ijU9vrB17lglt39rb9fXds6W3bksbjEbgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNWpgwJPck+Rwkt3HLDsryeNJXuruz+x3TEnSUsMcgd8LXLVk2W3AE1V1IfBE91ySdBINDHhVPQm8uWTx1cCO7vEO4JrJjiVJGmTUc+DnVtVBgO7+nJVWTLItyXyS+YWFhRFfTpK0VO9/iVlV26tqrqrmZmZm+n45SVozRg34oSSzAN394cmNJEkaxqgBfwTY2j3eCnxvMuNIkoY1zGWE9wM/Ai5Ksj/JDcDtwJVJXgKu7J5Lkk6igd/IU1XXrfCjKyY8iyTpBPhOTElqlAGXpEYZcGmtWbeBJL3cZjdumvberSl+K7201hx5hwtu3dnLpvfdsaWX7Wp5HoFLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqPWj/PLSfYCbwNHgHeram4SQ0mSBhsr4J3fr6o3JrAdSdIJ8BSKJDVq3IAX8FiSXUm2LbdCkm1J5pPMLywsjPlyktay2Y2bSNLLbXbjpmnv3gkb9xTK5VX1WpJzgMeTvFhVTx67QlVtB7YDzM3N1ZivJ2kNe/3Aq1xw685etr3vji29bLdPYx2BV9Vr3f1h4GHgskkMJUkabOSAJzk9yRlHHwOfAnZPajBJ0vGNcwrlXODhJEe38+2q+v5EppIkDTRywKvqZeC3JziLJOkEeBmhJDXKgJ8EfV76JGntmsQ7MTWAlz5J6oNH4JLUKAMuSY0y4JLUKAMuSY0y4JLUKK9CkTQ56zZ4eetJZMAlTc6Rd3q7ZBa8bHYpT6FIUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1aqyAJ7kqyU+S/DTJbZMaSpI02MgBT7IO+Fvg08DFwHVJLp7UYJKk4xvnCPwy4KdV9XJV/QL4DnD1ZMaSJA0yTsDPA1495vn+bpkk6SRIVY32i8m1wB9W1Z93z68HLquqLy5ZbxuwrXt6EfCT0cc95Z0NvDHtIU6StbKva2U/Ye3sa4v7eUFVzSxdOM630u8Hzj/m+UbgtaUrVdV2YPsYr9OMJPNVNTftOU6GtbKva2U/Ye3s62raz3FOofwrcGGSDyf5VeDzwCOTGUuSNMjIR+BV9W6Sm4AfAOuAe6rqhYlNJkk6rnFOoVBVjwKPTmiW1WBNnCrqrJV9XSv7CWtnX1fNfo78l5iSpOnyrfSS1CgDPiFJ1iX5cZKd056lT0n2Jnk+ybNJ5qc9T5+SfCjJg0leTLInye9Oe6ZJS3JR92d59PZWklumPVdfkvxFkheS7E5yf5L3TXumcXgKZUKS/CUwB3ywqrZMe56+JNkLzFVVa9fRnrAkO4B/qaq7uiutTquqn015rN50H49xAPidqto37XkmLcl5wFPAxVX1v0keAB6tqnunO9noPAKfgCQbgT8C7pr2LJqMJB8EPg7cDVBVv1jN8e5cAfz7aoz3MdYD70+yHjiNZd670hIDPhl/A/wV8N6U5zgZCngsya7uXbar1W8AC8DfdafG7kpy+rSH6tnngfunPURfquoA8DXgFeAg8N9V9dh0pxqPAR9Tki3A4araNe1ZTpLLq+qjLH4K5ReSfHzaA/VkPfBR4M6quhT4H2DVfmRyd4ros8A/TnuWviQ5k8UP3Psw8OvA6Un+dLpTjceAj+9y4LPdueHvAH+Q5O+nO1J/quq17v4w8DCLn0q5Gu0H9lfV093zB1kM+mr1aeCZqjo07UF69EngP6pqoareAR4Cfm/KM43FgI+pqv66qjZW1WYW/xf0n6qq6f+qryTJ6UnOOPoY+BSwe7pT9aOqXgdeTXJRt+gK4N+mOFLfrmMVnz7pvAJ8LMlpScLin+meKc80lrHeiak151zg4cV/9lkPfLuqvj/dkXr1ReC+7vTCy8CfTXmeXiQ5DbgSuHHas/Spqp5O8iDwDPAu8GMaf1emlxFKUqM8hSJJjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktSo/wNcgQ6jXJpDfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.arange(min(X[:,0]) -1,max(X[:,0])+1,0.4)\n",
    "\n",
    "plt.hist(X[:,0],bins,histtype='bar',ec='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c2d311",
   "metadata": {},
   "source": [
    "The distribution is kind of like Normal/ Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108eee64",
   "metadata": {},
   "source": [
    "## Convert to Dataframe with column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c6acb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.append(X,y.reshape(y.shape[0],1),axis=1)\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "\n",
    "dataset = dataset.rename(columns={0:'sepal length',1:'sepal width',2:'petal length',3:'petal width',4:'class'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a390a5d",
   "metadata": {},
   "source": [
    "## Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df51f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_shuffle(dataset):\n",
    "    for i in range(100):\n",
    "        dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "    return dataset\n",
    "\n",
    "dataset = Random_shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3939a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4abb74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessing(dataset):\n",
    "    X = dataset.drop([dataset.columns[-1]],axis=1)\n",
    "    y = dataset[dataset.columns[-1]]\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "X, y = PreProcessing(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91769bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed976c0a",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08ecba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert_to_numpy_array(array):\n",
    "    arr = np.fromiter(array.values(),dtype=float)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a8016",
   "metadata": {},
   "source": [
    "# Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fbda48",
   "metadata": {},
   "source": [
    "### Prior Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec09ee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probability for setosa: 0.333\n",
      "Prior Probability for versicolor: 0.333\n",
      "Prior Probability for virginica: 0.333\n"
     ]
    }
   ],
   "source": [
    "##Calculate the Prior Probabilites\n",
    "def Prior_Probability(y):\n",
    "    \n",
    "    total_samples = y.shape[0]\n",
    "    setosa = len(y[y==0])/total_samples\n",
    "    versicolor = len(y[y==1])/total_samples\n",
    "    virginica = len(y[y==2])/total_samples\n",
    "    \n",
    "    Prior_Prob = {\n",
    "        0 : format(setosa,\".3f\"),\n",
    "        1: format(versicolor,\".3f\"),\n",
    "        2: format(virginica,\".3f\")\n",
    "    }\n",
    "    map_class_to_label = {\n",
    "        0: \"setosa\",\n",
    "        1: \"versicolor\",\n",
    "        2: \"virginica\"\n",
    "    }\n",
    "    return Prior_Prob,map_class_to_label\n",
    "\n",
    "\n",
    "Prior_Prob,class_to_label_map = Prior_Probability(y)\n",
    "\n",
    "print(\"Prior Probability for setosa:\",Prior_Prob[0])\n",
    "print(\"Prior Probability for versicolor:\",Prior_Prob[1])\n",
    "print(\"Prior Probability for virginica:\",Prior_Prob[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2c878",
   "metadata": {},
   "source": [
    "### Mean & Variance for Each Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "666193e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tSepal Length\tSepal Width\tPetal Length\tPetal Width\n",
      "Mean\t\t 5.843 \t\t 3.057 \t\t 3.758 \t\t 1.199\n",
      "\n",
      "Variance\t 0.681 \t\t 0.189 \t\t 3.096 \t\t 0.577\n"
     ]
    }
   ],
   "source": [
    "def Calc_mean_variance(x):\n",
    "    features_mean = np.mean(x,axis=0)\n",
    "    \n",
    "    mean_of_features = {\n",
    "        0: format(features_mean['sepal length'],\".3f\"),\n",
    "        1: format(features_mean['sepal width'],\".3f\"),\n",
    "        2: format(features_mean['petal length'],\".3f\"),\n",
    "        3: format(features_mean['petal width'],\".3f\")\n",
    "    }\n",
    "    \n",
    "    features_variance = np.var(x,axis=0)\n",
    "    \n",
    "    var_of_features = {\n",
    "        0: format(features_variance['sepal length'],\".3f\"),\n",
    "        1: format(features_variance['sepal width'],\".3f\"),\n",
    "        2: format(features_variance['petal length'],\".3f\"),\n",
    "        3: format(features_variance['petal width'],\".3f\")\n",
    "    }\n",
    "    \n",
    "    return mean_of_features,var_of_features\n",
    "\n",
    "mean, variance  = Calc_mean_variance(X)\n",
    "\n",
    "print(\"\\t\\tSepal Length\\tSepal Width\\tPetal Length\\tPetal Width\")\n",
    "print(\"Mean\\t\\t\",mean[0],'\\t\\t',mean[1],'\\t\\t',mean[2],'\\t\\t',mean[3])\n",
    "print(\"\\nVariance\\t\",variance[0],'\\t\\t',variance[1],'\\t\\t',\\\n",
    "      variance[2],'\\t\\t',variance[3])\n",
    "\n",
    "mean = Convert_to_numpy_array(mean)\n",
    "variance = Convert_to_numpy_array(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8fc82",
   "metadata": {},
   "source": [
    "### Mean and Variance per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59dfba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calc_mean_var_per_class(dataset):\n",
    "    mean = []\n",
    "    variance = []\n",
    "    for i in np.unique(dataset['class']):\n",
    "        df = dataset[dataset['class'] == i]\n",
    "        mu,var = Calc_mean_variance(df.loc[:,df.columns!='class'])\n",
    "        mean_arr = Convert_to_numpy_array(mu)\n",
    "        variance_arr = Convert_to_numpy_array(var)\n",
    "        mean.append(mean_arr)\n",
    "        variance.append(variance_arr)\n",
    "    \n",
    "    return (np.array(mean),np.array(variance))\n",
    "\n",
    "mean_per_class,var_per_class = Calc_mean_var_per_class(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d0918",
   "metadata": {},
   "source": [
    "### Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2497f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianDistribution(x,mu,variance):\n",
    "    exp_numerator = (x - mu)**2\n",
    "    exp_denomerator = 2*variance\n",
    "    exp_part = np.exp(-(exp_numerator/exp_denomerator))\n",
    "    non_exp_part = 1/np.sqrt(2*math.pi*variance)\n",
    "    \n",
    "    Prob = non_exp_part * exp_part\n",
    "    \n",
    "    Gaussian_prob = Prob.prod(axis=1)\n",
    "    \n",
    "    return Gaussian_prob\n",
    "\n",
    "P_evidence = GaussianDistribution(X,mean,variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbeacc4",
   "metadata": {},
   "source": [
    "### Liklihood Estimate Probability(P(X/c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f8ac34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(x/c)\n",
    "def Calc_Liklihood(X,mean_per_class,var_per_class):\n",
    "    X = np.array(X)\n",
    "    result = []\n",
    "    Prob_likilihood = []\n",
    "    for i in range(len(X)):\n",
    "        Prob_likilihood.append(GaussianDistribution(X[i],mean_per_class,var_per_class))\n",
    "        \n",
    "    return np.array(Prob_likilihood)\n",
    "\n",
    "Prob_liklihood = Calc_Liklihood(X,mean_per_class,var_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baba46a",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50f502d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(model,X,P_evidence):\n",
    "    Prob_liklihood = Calc_Liklihood(X,model[\"mean_per_class\"],model[\"var_per_class\"])\n",
    "    Prior_Prob = Convert_to_numpy_array(model[\"P(C)\"])\n",
    "    P_evidence = np.array(P_evidence).reshape(P_evidence.shape[0],1)\n",
    "    Prob_outcome = (Prob_liklihood * Prior_Prob.T)/P_evidence\n",
    "    Posterier_prob = np.argmax(Prob_outcome,axis=1)\n",
    "    return Posterier_prob\n",
    "\n",
    "model = {\n",
    "        \"P(C)\": Prior_Prob,\n",
    "        \"P(X)\": P_evidence,\n",
    "        \"mean_per_class\": mean_per_class,\n",
    "        \"var_per_class\": var_per_class,\n",
    "        \"mean\": mean,\n",
    "        \"variance\": variance\n",
    "    }\n",
    "Posterier_prob = Predict(model,X,P_evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e88a12cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the entire data: 96.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy on the entire data:\",np.mean(y==Posterier_prob)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352a4c69",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d791916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X,y):\n",
    "    \n",
    "    Prior_Prob,_ = Prior_Probability(y)\n",
    "    df = pd.concat([X,y],axis=1)\n",
    "    mean_per_class,var_per_class = Calc_mean_var_per_class(df)\n",
    "    mean, variance  = Calc_mean_variance(X)\n",
    "    mean = Convert_to_numpy_array(mean)\n",
    "    variance = Convert_to_numpy_array(variance)\n",
    "    P_evidence = GaussianDistribution(X,mean,variance)\n",
    "    \n",
    "    model = {\n",
    "        \"P(C)\": Prior_Prob,\n",
    "        \"P(X)\": P_evidence,\n",
    "        \"mean_per_class\": mean_per_class,\n",
    "        \"var_per_class\": var_per_class,\n",
    "        \"mean\": mean,\n",
    "        \"variance\": variance\n",
    "    }\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00f8314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41157bc8",
   "metadata": {},
   "source": [
    "## Accuracy on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e213d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the entire data: 95.55555555555556 %\n"
     ]
    }
   ],
   "source": [
    "Posterier_prob = Predict(model,X_train,model[\"P(X)\"])\n",
    "\n",
    "print(\"The accuracy on the entire data:\",np.mean(y_train==Posterier_prob)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30afecb",
   "metadata": {},
   "source": [
    "## Accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5905a2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the entire data: 93.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "P_evidence = GaussianDistribution(X_test,model[\"mean\"],model[\"variance\"])\n",
    "\n",
    "Posterier_prob = Predict(model,X_test,P_evidence)\n",
    "\n",
    "print(\"The accuracy on the entire data:\",np.mean(y_test==Posterier_prob)*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
